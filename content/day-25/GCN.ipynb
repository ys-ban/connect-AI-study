{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GCN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJ-i1PBsUmLp"
      },
      "source": [
        "# import library required"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzR2UKK8VVfN",
        "outputId": "00517d96-27ef-4e19-f5d6-7c6b6af8f6c3"
      },
      "source": [
        "! pip install dgl"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dgl\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/b6/5450e9bb80842ab58a6ee8c0da8c7d738465703bceb576bd7e9782c65391/dgl-0.6.0-cp37-cp37m-manylinux1_x86_64.whl (4.2MB)\n",
            "\u001b[K     |████████████████████████████████| 4.2MB 6.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (2.23.0)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl) (2.5)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (1.19.5)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl) (1.4.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl) (2020.12.5)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.1->dgl) (4.4.2)\n",
            "Installing collected packages: dgl\n",
            "Successfully installed dgl-0.6.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gc42WF-PU84o",
        "outputId": "c07e889a-fe81-4281-d29f-703db9a062d4"
      },
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import dgl  # Deep Graph Library\n",
        "from dgl.data import CoraGraphDataset\n",
        "from dgl.nn.pytorch.conv import SAGEConv\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n",
            "Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_dX4R1yTVRGc"
      },
      "source": [
        "# load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eu_5Fb2YVm7k",
        "outputId": "98ee3e8b-b265-45b9-f67b-767df9f0109e"
      },
      "source": [
        "G = CoraGraphDataset()\n",
        "num_classes = G.num_classes\n",
        "G = G[0]\n",
        "features = G.ndata['feat']\n",
        "input_feature_dim = features.shape[1]\n",
        "labels = G.ndata['label']\n",
        "train_mask = G.ndata['train_mask']\n",
        "test_mask = G.ndata['test_mask']"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading /root/.dgl/cora_v2.zip from https://data.dgl.ai/dataset/cora_v2.zip...\n",
            "Extracting file to /root/.dgl/cora_v2\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 2708\n",
            "  NumEdges: 10556\n",
            "  NumFeats: 1433\n",
            "  NumClasses: 7\n",
            "  NumTrainingSamples: 140\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done saving data into cached files.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUo1Z4zuZ9mE"
      },
      "source": [
        "# modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWk7ZWUUZ8iN"
      },
      "source": [
        "# 하이퍼파라미터 초기화\n",
        "dropout_p = 0.5\n",
        "learning_rate = 1e-2\n",
        "num_epochs = 50\n",
        "num_hidden_dim = 128\n",
        "num_layers = 2\n",
        "weight_decay = 5e-4\n",
        "aggregator_type = \"gcn\""
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqpyImD2V9Cz"
      },
      "source": [
        "class GraphSAGE(nn.Module):\n",
        "    def __init__(self, graph, in_feat_dim, num_hidden_dim, num_classes, num_layers, activation_fun, dropout_p, aggregator_type):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        self.layers = nn.ModuleList()\n",
        "        self.graph = graph\n",
        "        self.layers.append(SAGEConv(in_feat_dim, num_hidden_dim, aggregator_type, dropout_p, activation_fun))\n",
        "\n",
        "        for i in range(num_layers):\n",
        "            self.layers.append(SAGEConv(num_hidden_dim, num_hidden_dim, aggregator_type, dropout_p, activation_fun))\n",
        "        \n",
        "        self.layers.append(SAGEConv(num_hidden_dim, num_classes, aggregator_type, dropout_p, activation=None))\n",
        "    \n",
        "    def forward(self, features):\n",
        "        x = features\n",
        "        for layer in self.layers:\n",
        "            x = layer(self.graph, x)\n",
        "        return x\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goD4gbF4Ybb7"
      },
      "source": [
        "# 모델 학습 결과를 평가할 함수\n",
        "def evaluate_train(model, features, labels, mask):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(features)\n",
        "        logits = logits[mask]\n",
        "        labels = labels[mask]\n",
        "        _, indices = torch.max(logits, dim=1)\n",
        "        correct = torch.sum(indices == labels)\n",
        "        return correct.item() * 1.0 / len(labels)\n",
        "\n",
        "def evaluate_test(model, features, labels, mask):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(features)\n",
        "        logits = logits[mask]\n",
        "        labels = labels[mask]\n",
        "        _, indices = torch.max(logits, dim=1)\n",
        "        macro_f1 = f1_score(labels, indices, average = 'macro')\n",
        "        correct = torch.sum(indices == labels)\n",
        "        return correct.item() * 1.0 / len(labels), macro_f1"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjnBpKvoXs_R"
      },
      "source": [
        "def train(model, loss_fun, features, labels, train_mask, optim, num_epochs):\n",
        "    running_time = []\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        start_t = time.time()\n",
        "        logits = model(features)\n",
        "        loss = loss_fun(logits[train_mask], labels[train_mask])\n",
        "        optim.zero_grad()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "        running_time.append(time.time()-start_t)\n",
        "        acc = evaluate_train(model, features, labels,train_mask)\n",
        "        print(f\"Epoch: {epoch}\\tTime: {running_time[epoch]:.2f}\\tLoss: {loss.item(): .4f}\\tAccuracy: {acc}\")\n",
        "\n",
        "def test(model, features, labels, test_mask):\n",
        "    acc, macro_f1 = evaluate_test(model, features, labels, test_mask)\n",
        "    print(f\"Test Acc: {acc: .4f}\")\n",
        "    print(f\"Test Macro-f1: {macro_f1: .4f}\")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R3P7XuVvZaPn",
        "outputId": "59dccad4-0bac-47bb-d01b-f46fe2d1b17d"
      },
      "source": [
        "model = GraphSAGE(G, input_feature_dim, num_hidden_dim, num_classes, num_layers, F.relu, dropout_p, aggregator_type)\n",
        "print(model)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GraphSAGE(\n",
            "  (layers): ModuleList(\n",
            "    (0): SAGEConv(\n",
            "      (feat_drop): Dropout(p=0.5, inplace=False)\n",
            "      (fc_neigh): Linear(in_features=1433, out_features=128, bias=True)\n",
            "    )\n",
            "    (1): SAGEConv(\n",
            "      (feat_drop): Dropout(p=0.5, inplace=False)\n",
            "      (fc_neigh): Linear(in_features=128, out_features=128, bias=True)\n",
            "    )\n",
            "    (2): SAGEConv(\n",
            "      (feat_drop): Dropout(p=0.5, inplace=False)\n",
            "      (fc_neigh): Linear(in_features=128, out_features=128, bias=True)\n",
            "    )\n",
            "    (3): SAGEConv(\n",
            "      (feat_drop): Dropout(p=0.5, inplace=False)\n",
            "      (fc_neigh): Linear(in_features=128, out_features=7, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNxeTK8UaIOc"
      },
      "source": [
        "loss_fun = nn.CrossEntropyLoss()\n",
        "optim = torch.optim.Adam(model.parameters(), lr = learning_rate, weight_decay=weight_decay)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwfC4-yEamMW",
        "outputId": "7384c045-b9d8-4ba9-a47c-a47ec5f28cfc"
      },
      "source": [
        "train(model, loss_fun, features, labels, train_mask, optim, num_epochs)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0\tTime: 0.15\tLoss:  1.9969\tAccuracy: 0.4357142857142857\n",
            "Epoch: 1\tTime: 0.13\tLoss:  1.7909\tAccuracy: 0.42142857142857143\n",
            "Epoch: 2\tTime: 0.13\tLoss:  1.6590\tAccuracy: 0.5214285714285715\n",
            "Epoch: 3\tTime: 0.12\tLoss:  1.4744\tAccuracy: 0.8928571428571429\n",
            "Epoch: 4\tTime: 0.13\tLoss:  1.2051\tAccuracy: 0.8928571428571429\n",
            "Epoch: 5\tTime: 0.13\tLoss:  0.8743\tAccuracy: 0.9214285714285714\n",
            "Epoch: 6\tTime: 0.13\tLoss:  0.6431\tAccuracy: 0.9214285714285714\n",
            "Epoch: 7\tTime: 0.13\tLoss:  0.4467\tAccuracy: 0.95\n",
            "Epoch: 8\tTime: 0.13\tLoss:  0.2938\tAccuracy: 0.9642857142857143\n",
            "Epoch: 9\tTime: 0.13\tLoss:  0.2188\tAccuracy: 0.9642857142857143\n",
            "Epoch: 10\tTime: 0.13\tLoss:  0.1483\tAccuracy: 0.9785714285714285\n",
            "Epoch: 11\tTime: 0.13\tLoss:  0.1259\tAccuracy: 0.9857142857142858\n",
            "Epoch: 12\tTime: 0.13\tLoss:  0.0831\tAccuracy: 0.9928571428571429\n",
            "Epoch: 13\tTime: 0.13\tLoss:  0.0832\tAccuracy: 0.9928571428571429\n",
            "Epoch: 14\tTime: 0.13\tLoss:  0.0347\tAccuracy: 1.0\n",
            "Epoch: 15\tTime: 0.13\tLoss:  0.0709\tAccuracy: 0.9928571428571429\n",
            "Epoch: 16\tTime: 0.14\tLoss:  0.0291\tAccuracy: 0.9785714285714285\n",
            "Epoch: 17\tTime: 0.12\tLoss:  0.0466\tAccuracy: 0.9785714285714285\n",
            "Epoch: 18\tTime: 0.13\tLoss:  0.0402\tAccuracy: 0.9928571428571429\n",
            "Epoch: 19\tTime: 0.13\tLoss:  0.0822\tAccuracy: 1.0\n",
            "Epoch: 20\tTime: 0.13\tLoss:  0.0159\tAccuracy: 0.9785714285714285\n",
            "Epoch: 21\tTime: 0.13\tLoss:  0.0508\tAccuracy: 0.9928571428571429\n",
            "Epoch: 22\tTime: 0.13\tLoss:  0.0339\tAccuracy: 1.0\n",
            "Epoch: 23\tTime: 0.13\tLoss:  0.0234\tAccuracy: 0.9928571428571429\n",
            "Epoch: 24\tTime: 0.13\tLoss:  0.0176\tAccuracy: 0.9928571428571429\n",
            "Epoch: 25\tTime: 0.13\tLoss:  0.0143\tAccuracy: 1.0\n",
            "Epoch: 26\tTime: 0.13\tLoss:  0.0390\tAccuracy: 0.9857142857142858\n",
            "Epoch: 27\tTime: 0.13\tLoss:  0.0109\tAccuracy: 1.0\n",
            "Epoch: 28\tTime: 0.13\tLoss:  0.0055\tAccuracy: 1.0\n",
            "Epoch: 29\tTime: 0.13\tLoss:  0.0290\tAccuracy: 1.0\n",
            "Epoch: 30\tTime: 0.13\tLoss:  0.0171\tAccuracy: 0.9928571428571429\n",
            "Epoch: 31\tTime: 0.13\tLoss:  0.0355\tAccuracy: 1.0\n",
            "Epoch: 32\tTime: 0.13\tLoss:  0.0120\tAccuracy: 1.0\n",
            "Epoch: 33\tTime: 0.13\tLoss:  0.0369\tAccuracy: 0.9857142857142858\n",
            "Epoch: 34\tTime: 0.13\tLoss:  0.0388\tAccuracy: 0.9857142857142858\n",
            "Epoch: 35\tTime: 0.13\tLoss:  0.1012\tAccuracy: 1.0\n",
            "Epoch: 36\tTime: 0.13\tLoss:  0.0327\tAccuracy: 0.9928571428571429\n",
            "Epoch: 37\tTime: 0.13\tLoss:  0.0256\tAccuracy: 0.9642857142857143\n",
            "Epoch: 38\tTime: 0.12\tLoss:  0.1428\tAccuracy: 1.0\n",
            "Epoch: 39\tTime: 0.13\tLoss:  0.1814\tAccuracy: 0.9857142857142858\n",
            "Epoch: 40\tTime: 0.13\tLoss:  0.0405\tAccuracy: 0.9857142857142858\n",
            "Epoch: 41\tTime: 0.13\tLoss:  0.0532\tAccuracy: 0.9857142857142858\n",
            "Epoch: 42\tTime: 0.13\tLoss:  0.1032\tAccuracy: 1.0\n",
            "Epoch: 43\tTime: 0.12\tLoss:  0.0346\tAccuracy: 0.9785714285714285\n",
            "Epoch: 44\tTime: 0.13\tLoss:  0.1418\tAccuracy: 1.0\n",
            "Epoch: 45\tTime: 0.13\tLoss:  0.0293\tAccuracy: 1.0\n",
            "Epoch: 46\tTime: 0.12\tLoss:  0.0379\tAccuracy: 0.9928571428571429\n",
            "Epoch: 47\tTime: 0.12\tLoss:  0.0323\tAccuracy: 0.9928571428571429\n",
            "Epoch: 48\tTime: 0.13\tLoss:  0.0388\tAccuracy: 1.0\n",
            "Epoch: 49\tTime: 0.12\tLoss:  0.0378\tAccuracy: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UTl3SS7uavlW",
        "outputId": "dbd98e67-f368-4a16-8370-43cc3988453f"
      },
      "source": [
        "test(model, features, labels, test_mask)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Acc:  0.7920\n",
            "Test Macro-f1:  0.7799\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5IZkCLzbonL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}