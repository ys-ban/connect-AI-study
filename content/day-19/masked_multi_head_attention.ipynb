{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "masked_multi_head_attention.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_mRUNOH1gIRO"
      },
      "source": [
        "# Masked Multi-Head Attetion\n",
        "\n",
        "1. implement Masked Multi-head Attention\n",
        "2. implement Encoder-Decoder Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IlbENBc4gjFH"
      },
      "source": [
        "## import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PB6Linmgmen"
      },
      "source": [
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import math"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEjEqWZ3gvy3"
      },
      "source": [
        "## Data refinement\n",
        "\n",
        "to observe values and shapes in more detail, decrease the size of sample"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ac2IhTzHhE5a"
      },
      "source": [
        "pad_id = 0\n",
        "vocab_size = 100\n",
        "\n",
        "data = [\n",
        "  [62, 13, 47, 39, 78, 33, 56, 13],\n",
        "  [60, 96, 51, 32, 90],\n",
        "  [35, 45, 48, 65, 91, 99, 92, 10, 3, 21],\n",
        "  [66, 88, 98, 47],\n",
        "  [77, 65, 51, 77, 19, 15, 35, 19, 23]\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "He3hkJ9KhIF2"
      },
      "source": [
        "def padding(data):\n",
        "  max_len = len(max(data, key = len))\n",
        "  print(f\"\\nMaximum sequence length: {max_len}\")\n",
        "\n",
        "  for i, seq in enumerate(tqdm(data)):\n",
        "    if len(seq)<max_len:\n",
        "      data[i] = seq + [pad_id] * (max_len-len(seq))\n",
        "  \n",
        "  return data, max_len"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f30XfO_-hdCk",
        "outputId": "313dd22e-d94d-46d3-bce5-2d8d5b95c802"
      },
      "source": [
        "data, max_len = padding(data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:00<00:00, 1282.27it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Maximum sequence length: 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anL4HC-Ghot_",
        "outputId": "3634d1f0-272f-4ad9-cc13-8975b7e9ea92"
      },
      "source": [
        "data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[62, 13, 47, 39, 78, 33, 56, 13, 0, 0],\n",
              " [60, 96, 51, 32, 90, 0, 0, 0, 0, 0],\n",
              " [35, 45, 48, 65, 91, 99, 92, 10, 3, 21],\n",
              " [66, 88, 98, 47, 0, 0, 0, 0, 0, 0],\n",
              " [77, 65, 51, 77, 19, 15, 35, 19, 23, 0]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nf5HwSqKh3w7"
      },
      "source": [
        "## Set Hyperparameters and Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpIYyudqh9T1"
      },
      "source": [
        "d_model = 8   # hidden_size of model\n",
        "num_heads = 2 # the number of heads\n",
        "inf = 1e12"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3z9BgbFiH_S"
      },
      "source": [
        "embedding = nn.Embedding(vocab_size, d_model)\n",
        "\n",
        "# B: batch size, L: maximum sequence length\n",
        "batch = torch.LongTensor(data)  # (B, L)\n",
        "batch_emb = embedding(batch)    # (B, L, d_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eO_Jn4Arijqr",
        "outputId": "baf0a6ed-7c9b-4412-d38c-5eb566ed0685"
      },
      "source": [
        "print(batch_emb)\n",
        "print(batch_emb.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[-1.3026, -0.1526,  0.6810,  1.1066,  0.9289,  0.8636, -0.2004,\n",
            "          -1.2961],\n",
            "         [ 1.7260,  0.4165,  1.6349, -0.7804, -0.8938, -1.2166,  1.1108,\n",
            "           1.0554],\n",
            "         [-0.4178, -1.0309,  1.5177,  1.2440, -0.9330,  1.5603, -0.3513,\n",
            "          -0.6272],\n",
            "         [ 0.3972,  0.6800,  1.1626, -0.4897,  0.4080,  1.3365, -0.4225,\n",
            "          -0.7903],\n",
            "         [-0.6695,  0.2338,  1.7958, -0.4542, -0.7971,  0.0782,  0.1521,\n",
            "          -0.7014],\n",
            "         [-0.4815,  1.1098,  0.3544,  0.0872, -0.2117, -1.0081, -0.0151,\n",
            "           0.1299],\n",
            "         [-0.0355, -1.5054,  0.0409,  1.2526, -0.7749,  1.4308,  0.4267,\n",
            "          -0.1816],\n",
            "         [ 1.7260,  0.4165,  1.6349, -0.7804, -0.8938, -1.2166,  1.1108,\n",
            "           1.0554],\n",
            "         [ 0.1417,  0.6713,  0.3581, -1.1337, -2.0103, -1.4942,  0.7149,\n",
            "           0.4122],\n",
            "         [ 0.1417,  0.6713,  0.3581, -1.1337, -2.0103, -1.4942,  0.7149,\n",
            "           0.4122]],\n",
            "\n",
            "        [[-0.2745,  2.0970, -1.2221, -0.1496, -0.8902,  0.6538, -0.1367,\n",
            "          -0.3457],\n",
            "         [-0.4163, -1.4408,  0.4335, -0.7271,  0.1217,  0.3706,  0.5846,\n",
            "          -0.6412],\n",
            "         [ 0.4640, -0.7645,  0.2385,  0.2946,  0.3486,  0.5717, -0.2096,\n",
            "          -0.5909],\n",
            "         [-2.3756,  0.8369, -0.7565,  0.1401, -0.5169, -0.3105, -0.5474,\n",
            "           0.9767],\n",
            "         [-1.2556,  1.4957,  1.5494,  0.9872,  1.2974, -1.0292,  0.1543,\n",
            "          -0.8012],\n",
            "         [ 0.1417,  0.6713,  0.3581, -1.1337, -2.0103, -1.4942,  0.7149,\n",
            "           0.4122],\n",
            "         [ 0.1417,  0.6713,  0.3581, -1.1337, -2.0103, -1.4942,  0.7149,\n",
            "           0.4122],\n",
            "         [ 0.1417,  0.6713,  0.3581, -1.1337, -2.0103, -1.4942,  0.7149,\n",
            "           0.4122],\n",
            "         [ 0.1417,  0.6713,  0.3581, -1.1337, -2.0103, -1.4942,  0.7149,\n",
            "           0.4122],\n",
            "         [ 0.1417,  0.6713,  0.3581, -1.1337, -2.0103, -1.4942,  0.7149,\n",
            "           0.4122]],\n",
            "\n",
            "        [[ 0.1223,  0.6169,  0.7290,  0.4083,  0.7062,  1.8156, -0.0751,\n",
            "          -0.4554],\n",
            "         [ 2.2132,  0.9685,  0.0591, -0.3701, -0.2621,  0.9165, -0.7100,\n",
            "          -0.5771],\n",
            "         [-0.1804,  0.6321, -0.4053, -0.5819, -0.3348, -0.2943, -0.0116,\n",
            "           1.9235],\n",
            "         [ 2.0116,  0.4897,  0.7985,  0.1053, -0.0058,  0.4870, -0.6129,\n",
            "          -0.4275],\n",
            "         [ 0.5423, -1.1099, -1.5921,  0.1858,  0.0417, -0.1902,  0.1481,\n",
            "          -0.0473],\n",
            "         [-0.7926,  0.2322,  1.1959, -1.7895,  1.4484,  1.2641, -0.0159,\n",
            "          -0.8674],\n",
            "         [-1.1430, -1.3291, -0.5344, -1.2812, -0.6215,  0.5565, -0.2445,\n",
            "          -1.9233],\n",
            "         [-0.7300,  0.8581,  0.6135, -1.1418, -0.2597,  1.7199,  1.0692,\n",
            "          -0.0585],\n",
            "         [ 1.4892, -0.6357,  0.2366,  1.0457, -1.4671, -0.6918, -0.6506,\n",
            "          -0.8321],\n",
            "         [ 0.3842,  0.2070,  0.7096,  0.3982,  0.6464,  0.6149, -0.2896,\n",
            "          -0.9844]],\n",
            "\n",
            "        [[-1.7656,  0.7169,  0.7446, -0.6484,  0.8205,  1.4015,  0.5811,\n",
            "           1.5298],\n",
            "         [-0.3570,  0.8389,  1.2502,  0.5078, -1.4123, -0.0692,  0.6543,\n",
            "          -0.5008],\n",
            "         [-0.4011,  0.4900,  0.4430,  0.9580, -0.1569, -0.1660,  1.5297,\n",
            "           0.0580],\n",
            "         [-0.4178, -1.0309,  1.5177,  1.2440, -0.9330,  1.5603, -0.3513,\n",
            "          -0.6272],\n",
            "         [ 0.1417,  0.6713,  0.3581, -1.1337, -2.0103, -1.4942,  0.7149,\n",
            "           0.4122],\n",
            "         [ 0.1417,  0.6713,  0.3581, -1.1337, -2.0103, -1.4942,  0.7149,\n",
            "           0.4122],\n",
            "         [ 0.1417,  0.6713,  0.3581, -1.1337, -2.0103, -1.4942,  0.7149,\n",
            "           0.4122],\n",
            "         [ 0.1417,  0.6713,  0.3581, -1.1337, -2.0103, -1.4942,  0.7149,\n",
            "           0.4122],\n",
            "         [ 0.1417,  0.6713,  0.3581, -1.1337, -2.0103, -1.4942,  0.7149,\n",
            "           0.4122],\n",
            "         [ 0.1417,  0.6713,  0.3581, -1.1337, -2.0103, -1.4942,  0.7149,\n",
            "           0.4122]],\n",
            "\n",
            "        [[ 0.7278,  0.5658, -0.8835, -0.3959,  0.9557,  1.7089,  1.4359,\n",
            "           0.6466],\n",
            "         [ 2.0116,  0.4897,  0.7985,  0.1053, -0.0058,  0.4870, -0.6129,\n",
            "          -0.4275],\n",
            "         [ 0.4640, -0.7645,  0.2385,  0.2946,  0.3486,  0.5717, -0.2096,\n",
            "          -0.5909],\n",
            "         [ 0.7278,  0.5658, -0.8835, -0.3959,  0.9557,  1.7089,  1.4359,\n",
            "           0.6466],\n",
            "         [ 1.5219, -0.9315, -0.0806,  0.3713,  0.0181, -0.9085, -0.1937,\n",
            "          -0.3531],\n",
            "         [ 1.5041, -0.0664, -0.8750, -0.6212,  0.3634, -0.0903,  1.3508,\n",
            "           1.8948],\n",
            "         [ 0.1223,  0.6169,  0.7290,  0.4083,  0.7062,  1.8156, -0.0751,\n",
            "          -0.4554],\n",
            "         [ 1.5219, -0.9315, -0.0806,  0.3713,  0.0181, -0.9085, -0.1937,\n",
            "          -0.3531],\n",
            "         [ 0.1620,  0.0851,  0.9915,  0.2328, -0.3107,  0.4826, -0.5368,\n",
            "           0.3041],\n",
            "         [ 0.1417,  0.6713,  0.3581, -1.1337, -2.0103, -1.4942,  0.7149,\n",
            "           0.4122]]], grad_fn=<EmbeddingBackward>)\n",
            "torch.Size([5, 10, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B4MWVTbBioNO"
      },
      "source": [
        "## Masking\n",
        "\n",
        "the position whose value is `True` will be used for attention\n",
        "\n",
        "the position whose value is `False` will be masked"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5-Rnad9ejFtg",
        "outputId": "a3d044fb-feee-4779-ead0-fd8d6515f052"
      },
      "source": [
        "padding_mask = (batch !=pad_id).unsqueeze(1)  # (B, 1, L)\n",
        "\n",
        "print(padding_mask)\n",
        "print(padding_mask.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ True,  True,  True,  True,  True,  True,  True,  True, False, False]],\n",
            "\n",
            "        [[ True,  True,  True,  True,  True, False, False, False, False, False]],\n",
            "\n",
            "        [[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True]],\n",
            "\n",
            "        [[ True,  True,  True,  True, False, False, False, False, False, False]],\n",
            "\n",
            "        [[ True,  True,  True,  True,  True,  True,  True,  True,  True, False]]])\n",
            "torch.Size([5, 1, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ONQAICDsjSDp",
        "outputId": "0ff40929-116d-4649-af5c-b03dcb9d1f19"
      },
      "source": [
        "nopeak_mask = torch.ones([1, max_len, max_len], dtype = torch.bool) # (1, L, L)\n",
        "nopeak_mask = torch.tril(nopeak_mask) # (1, L, L)\n",
        "\n",
        "print(nopeak_mask)\n",
        "print(nopeak_mask.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ True, False, False, False, False, False, False, False, False, False],\n",
            "         [ True,  True, False, False, False, False, False, False, False, False],\n",
            "         [ True,  True,  True, False, False, False, False, False, False, False],\n",
            "         [ True,  True,  True,  True, False, False, False, False, False, False],\n",
            "         [ True,  True,  True,  True,  True, False, False, False, False, False],\n",
            "         [ True,  True,  True,  True,  True,  True, False, False, False, False],\n",
            "         [ True,  True,  True,  True,  True,  True,  True, False, False, False],\n",
            "         [ True,  True,  True,  True,  True,  True,  True,  True, False, False],\n",
            "         [ True,  True,  True,  True,  True,  True,  True,  True,  True, False],\n",
            "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True]]])\n",
            "torch.Size([1, 10, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpnM9vJbp8z_",
        "outputId": "042fa0d2-734e-4aa4-92d3-1e6bb9b7927f"
      },
      "source": [
        "mask = padding_mask & nopeak_mask # (B, L, L)\n",
        "\n",
        "print(mask)\n",
        "print(mask.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ True, False, False, False, False, False, False, False, False, False],\n",
            "         [ True,  True, False, False, False, False, False, False, False, False],\n",
            "         [ True,  True,  True, False, False, False, False, False, False, False],\n",
            "         [ True,  True,  True,  True, False, False, False, False, False, False],\n",
            "         [ True,  True,  True,  True,  True, False, False, False, False, False],\n",
            "         [ True,  True,  True,  True,  True,  True, False, False, False, False],\n",
            "         [ True,  True,  True,  True,  True,  True,  True, False, False, False],\n",
            "         [ True,  True,  True,  True,  True,  True,  True,  True, False, False],\n",
            "         [ True,  True,  True,  True,  True,  True,  True,  True, False, False],\n",
            "         [ True,  True,  True,  True,  True,  True,  True,  True, False, False]],\n",
            "\n",
            "        [[ True, False, False, False, False, False, False, False, False, False],\n",
            "         [ True,  True, False, False, False, False, False, False, False, False],\n",
            "         [ True,  True,  True, False, False, False, False, False, False, False],\n",
            "         [ True,  True,  True,  True, False, False, False, False, False, False],\n",
            "         [ True,  True,  True,  True,  True, False, False, False, False, False],\n",
            "         [ True,  True,  True,  True,  True, False, False, False, False, False],\n",
            "         [ True,  True,  True,  True,  True, False, False, False, False, False],\n",
            "         [ True,  True,  True,  True,  True, False, False, False, False, False],\n",
            "         [ True,  True,  True,  True,  True, False, False, False, False, False],\n",
            "         [ True,  True,  True,  True,  True, False, False, False, False, False]],\n",
            "\n",
            "        [[ True, False, False, False, False, False, False, False, False, False],\n",
            "         [ True,  True, False, False, False, False, False, False, False, False],\n",
            "         [ True,  True,  True, False, False, False, False, False, False, False],\n",
            "         [ True,  True,  True,  True, False, False, False, False, False, False],\n",
            "         [ True,  True,  True,  True,  True, False, False, False, False, False],\n",
            "         [ True,  True,  True,  True,  True,  True, False, False, False, False],\n",
            "         [ True,  True,  True,  True,  True,  True,  True, False, False, False],\n",
            "         [ True,  True,  True,  True,  True,  True,  True,  True, False, False],\n",
            "         [ True,  True,  True,  True,  True,  True,  True,  True,  True, False],\n",
            "         [ True,  True,  True,  True,  True,  True,  True,  True,  True,  True]],\n",
            "\n",
            "        [[ True, False, False, False, False, False, False, False, False, False],\n",
            "         [ True,  True, False, False, False, False, False, False, False, False],\n",
            "         [ True,  True,  True, False, False, False, False, False, False, False],\n",
            "         [ True,  True,  True,  True, False, False, False, False, False, False],\n",
            "         [ True,  True,  True,  True, False, False, False, False, False, False],\n",
            "         [ True,  True,  True,  True, False, False, False, False, False, False],\n",
            "         [ True,  True,  True,  True, False, False, False, False, False, False],\n",
            "         [ True,  True,  True,  True, False, False, False, False, False, False],\n",
            "         [ True,  True,  True,  True, False, False, False, False, False, False],\n",
            "         [ True,  True,  True,  True, False, False, False, False, False, False]],\n",
            "\n",
            "        [[ True, False, False, False, False, False, False, False, False, False],\n",
            "         [ True,  True, False, False, False, False, False, False, False, False],\n",
            "         [ True,  True,  True, False, False, False, False, False, False, False],\n",
            "         [ True,  True,  True,  True, False, False, False, False, False, False],\n",
            "         [ True,  True,  True,  True,  True, False, False, False, False, False],\n",
            "         [ True,  True,  True,  True,  True,  True, False, False, False, False],\n",
            "         [ True,  True,  True,  True,  True,  True,  True, False, False, False],\n",
            "         [ True,  True,  True,  True,  True,  True,  True,  True, False, False],\n",
            "         [ True,  True,  True,  True,  True,  True,  True,  True,  True, False],\n",
            "         [ True,  True,  True,  True,  True,  True,  True,  True,  True, False]]])\n",
            "torch.Size([5, 10, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qwJImelsqIN_"
      },
      "source": [
        "## Linear transformation & splitting into several heads"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82A_jVqxqSia"
      },
      "source": [
        "w_q = nn.Linear(d_model, d_model)\n",
        "w_k = nn.Linear(d_model, d_model)\n",
        "w_v = nn.Linear(d_model, d_model)\n",
        "\n",
        "w_0 = nn.Linear(d_model, d_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnmW0TR5qbSR",
        "outputId": "bba62e16-85d5-47b8-f507-2a32dee55094"
      },
      "source": [
        "q = w_q(batch_emb)\n",
        "k = w_k(batch_emb)\n",
        "v = w_v(batch_emb)\n",
        "\n",
        "batch_size = q.shape[0]\n",
        "d_k = d_model // num_heads\n",
        "\n",
        "q = q.view(batch_size, -1, num_heads, d_k)  # (B, L, num_heads, d_k)\n",
        "k = k.view(batch_size, -1, num_heads, d_k)  # (B, L, num_heads, d_k)\n",
        "v = v.view(batch_size, -1, num_heads, d_k)  # (B, L, num_heads, d_k)\n",
        "\n",
        "q = q.transpose(1, 2) # (B, num_heds, L, d_k)\n",
        "k = k.transpose(1, 2) # (B, num_heds, L, d_k)\n",
        "v = v.transpose(1, 2) # (B, num_heds, L, d_k)\n",
        "\n",
        "print(q.shape)\n",
        "print(k.shape)\n",
        "print(v.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 2, 10, 4])\n",
            "torch.Size([5, 2, 10, 4])\n",
            "torch.Size([5, 2, 10, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11Y0AACtt72E"
      },
      "source": [
        "## implement self-attention masking-applied"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRF68v-nuJ2q"
      },
      "source": [
        "attn_scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k) # (B, num_heads, L, L)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZVWHqsxwpxt",
        "outputId": "d21b6e3e-acda-46a6-ef5d-19a65911295b"
      },
      "source": [
        "masks = mask.unsqueeze(1) # (B, 1, L, L)\n",
        "masked_attn_scores = attn_scores.masked_fill_(masks == False, -1 * inf)  # (B, num_heads, L, L)\n",
        "\n",
        "print(masked_attn_scores)\n",
        "print(masked_attn_scores.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[-3.6156e-02, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 3.3317e-01, -1.4631e-01, -1.0000e+12, -1.0000e+12, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [-6.3422e-01,  1.1257e-01, -2.9731e-01, -1.0000e+12, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 2.4420e-02,  1.1599e-01, -9.1046e-02, -3.1467e-01, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [-3.6400e-01,  7.8098e-02, -2.4817e-01, -9.4597e-02, -3.0795e-02,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 2.9746e-01, -2.6459e-02,  1.7034e-01,  5.8131e-02,  4.9967e-02,\n",
            "            2.4040e-02, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [-4.1200e-01, -4.2126e-02, -1.2988e-01,  1.4401e-02, -1.3483e-01,\n",
            "            3.4365e-02, -9.8358e-02, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 3.3317e-01, -1.4631e-01,  1.8320e-01,  1.3197e-02,  2.4517e-03,\n",
            "           -2.7156e-03,  2.3298e-01, -1.4631e-01, -1.0000e+12, -1.0000e+12],\n",
            "          [-1.2727e-01, -1.9258e-01, -1.8241e-01, -2.7225e-01, -7.5308e-02,\n",
            "           -7.5490e-02, -9.6167e-02, -1.9258e-01, -1.0000e+12, -1.0000e+12],\n",
            "          [-1.2727e-01, -1.9258e-01, -1.8241e-01, -2.7225e-01, -7.5308e-02,\n",
            "           -7.5490e-02, -9.6167e-02, -1.9258e-01, -1.0000e+12, -1.0000e+12]],\n",
            "\n",
            "         [[-8.3324e-01, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 6.4521e-01,  1.9029e-02, -1.0000e+12, -1.0000e+12, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [-8.5204e-02,  1.1433e-01,  1.2217e-02, -1.0000e+12, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 7.4069e-01, -2.5657e-01,  7.5280e-01,  5.3238e-01, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [-1.0698e-01,  9.8121e-02,  1.7928e-01,  8.7505e-02,  1.3555e-01,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [-4.8587e-01,  2.2389e-01, -2.6323e-01, -2.0737e-01, -1.3719e-01,\n",
            "           -1.1984e-01, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [-6.8592e-02,  3.5770e-02, -1.7952e-02, -1.9188e-02, -1.2254e-02,\n",
            "           -2.5601e-02,  1.7205e-02, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 6.4521e-01,  1.9029e-02,  7.9425e-01,  7.1645e-01,  4.8988e-01,\n",
            "            1.6628e-02,  7.0411e-01,  1.9029e-02, -1.0000e+12, -1.0000e+12],\n",
            "          [ 2.9121e-02,  1.1346e-01,  3.5458e-01,  2.3148e-01,  1.0115e-01,\n",
            "           -1.3970e-01,  4.4533e-01,  1.1346e-01, -1.0000e+12, -1.0000e+12],\n",
            "          [ 2.9121e-02,  1.1346e-01,  3.5458e-01,  2.3148e-01,  1.0115e-01,\n",
            "           -1.3970e-01,  4.4533e-01,  1.1346e-01, -1.0000e+12, -1.0000e+12]]],\n",
            "\n",
            "\n",
            "        [[[-4.3968e-01, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 2.1435e-01, -1.1320e-01, -1.0000e+12, -1.0000e+12, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 2.0619e-02, -4.3559e-02, -2.7533e-02, -1.0000e+12, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 2.0368e-01, -6.1881e-02,  3.3797e-02, -1.4302e-02, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [-6.0278e-02,  1.2366e-01,  3.6690e-01, -5.5558e-01,  5.8300e-01,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [-1.5217e-01,  7.6794e-02, -1.5949e-01,  2.1180e-01, -1.8932e-01,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [-1.5217e-01,  7.6794e-02, -1.5949e-01,  2.1180e-01, -1.8932e-01,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [-1.5217e-01,  7.6794e-02, -1.5949e-01,  2.1180e-01, -1.8932e-01,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [-1.5217e-01,  7.6794e-02, -1.5949e-01,  2.1180e-01, -1.8932e-01,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [-1.5217e-01,  7.6794e-02, -1.5949e-01,  2.1180e-01, -1.8932e-01,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12]],\n",
            "\n",
            "         [[-6.7247e-02, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 5.4752e-02,  1.3363e-01, -1.0000e+12, -1.0000e+12, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 7.2796e-02,  9.2941e-02, -5.6289e-02, -1.0000e+12, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [-7.7198e-02, -3.6550e-01, -2.5117e-01, -3.3816e-01, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 9.7591e-02, -2.2846e-01, -6.4600e-01, -7.7217e-02, -1.2124e+00,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 9.3149e-02,  2.8596e-01,  1.7753e-01,  6.9611e-02, -3.8337e-01,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 9.3149e-02,  2.8596e-01,  1.7753e-01,  6.9611e-02, -3.8337e-01,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 9.3149e-02,  2.8596e-01,  1.7753e-01,  6.9611e-02, -3.8337e-01,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 9.3149e-02,  2.8596e-01,  1.7753e-01,  6.9611e-02, -3.8337e-01,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 9.3149e-02,  2.8596e-01,  1.7753e-01,  6.9611e-02, -3.8337e-01,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12]]],\n",
            "\n",
            "\n",
            "        [[[-1.1984e-01, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [-6.6744e-01, -1.2557e+00, -1.0000e+12, -1.0000e+12, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 9.1952e-02, -1.1173e-01,  5.9822e-02, -1.0000e+12, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [-3.3284e-01, -7.7547e-01,  8.1730e-02, -4.5049e-01, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [-9.8913e-02, -2.2059e-01,  1.5419e-01, -1.8038e-01,  1.7010e-01,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [-3.2006e-01, -3.6410e-01,  3.8489e-02, -2.0942e-01, -1.4078e-01,\n",
            "           -1.1233e-01, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [-8.9889e-01, -4.4958e-01,  2.7270e-01, -5.6917e-01, -9.5878e-02,\n",
            "           -3.3369e-01,  3.1687e-01, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [-3.4914e-01, -1.7937e-01,  1.6754e-01, -1.3449e-01, -6.7484e-04,\n",
            "           -2.4858e-01,  4.9624e-02, -3.1879e-01, -1.0000e+12, -1.0000e+12],\n",
            "          [-3.6156e-01, -3.8845e-01,  1.3203e-01, -3.6338e-01,  1.5234e-02,\n",
            "           -1.4028e-01,  1.4910e-01, -1.7572e-01, -1.0967e-01, -1.0000e+12],\n",
            "          [-8.4161e-02, -2.4062e-01,  2.1567e-02, -7.9040e-02, -3.7078e-02,\n",
            "           -7.0673e-02, -8.4985e-02, -1.9754e-01,  9.2979e-02,  3.8524e-02]],\n",
            "\n",
            "         [[ 4.6982e-01, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 9.7530e-01,  8.4808e-02, -1.0000e+12, -1.0000e+12, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 5.1226e-01,  4.0393e-01, -6.2007e-02, -1.0000e+12, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 6.7150e-01,  1.0162e-01, -1.8291e-02,  1.3598e-01, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [-2.9917e-01, -1.8478e-01, -6.3659e-02, -1.7615e-01, -8.0246e-02,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 4.4810e-01, -2.6010e-01,  1.1278e-01, -2.5327e-01, -1.1954e-02,\n",
            "            8.0602e-01, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [-3.6684e-01, -5.0207e-01,  1.4639e-01, -5.2936e-01, -7.9795e-02,\n",
            "           -1.6398e-01,  9.7636e-02, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 8.7043e-01,  5.7369e-03,  2.3944e-01,  4.9281e-02,  1.2511e-01,\n",
            "            1.0310e+00,  7.3917e-01,  9.8384e-01, -1.0000e+12, -1.0000e+12],\n",
            "          [-2.0814e-01,  2.0005e-03,  5.2610e-02, -7.3935e-02,  9.4904e-03,\n",
            "           -1.6817e-01, -4.4454e-02, -3.6970e-04, -3.0205e-02, -1.0000e+12],\n",
            "          [-2.0226e-02, -2.0236e-01,  9.3520e-02, -2.5534e-01, -2.0825e-02,\n",
            "            2.0717e-01,  3.1797e-01,  3.4844e-01, -2.3459e-01, -1.1697e-01]]],\n",
            "\n",
            "\n",
            "        [[[-1.4988e-01, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [-9.9437e-02, -3.3060e-02, -1.0000e+12, -1.0000e+12, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 4.7147e-02,  1.2781e-01,  2.1025e-01, -1.0000e+12, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [-4.7713e-01, -8.1020e-02, -5.3461e-01, -2.9731e-01, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 1.1296e-01, -1.6922e-01, -1.1397e-01, -1.8241e-01, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 1.1296e-01, -1.6922e-01, -1.1397e-01, -1.8241e-01, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 1.1296e-01, -1.6922e-01, -1.1397e-01, -1.8241e-01, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 1.1296e-01, -1.6922e-01, -1.1397e-01, -1.8241e-01, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 1.1296e-01, -1.6922e-01, -1.1397e-01, -1.8241e-01, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 1.1296e-01, -1.6922e-01, -1.1397e-01, -1.8241e-01, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12]],\n",
            "\n",
            "         [[ 5.4070e-01, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 4.6349e-01, -1.2925e-02, -1.0000e+12, -1.0000e+12, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 1.8112e-01, -9.6685e-02, -8.4897e-02, -1.0000e+12, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 1.3443e-01,  5.8962e-02,  4.8329e-02,  1.2217e-02, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 5.0510e-01,  4.3138e-02,  7.1303e-02,  3.5458e-01, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 5.0510e-01,  4.3138e-02,  7.1303e-02,  3.5458e-01, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 5.0510e-01,  4.3138e-02,  7.1303e-02,  3.5458e-01, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 5.0510e-01,  4.3138e-02,  7.1303e-02,  3.5458e-01, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 5.0510e-01,  4.3138e-02,  7.1303e-02,  3.5458e-01, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 5.0510e-01,  4.3138e-02,  7.1303e-02,  3.5458e-01, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12]]],\n",
            "\n",
            "\n",
            "        [[[-3.0623e-01, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [-6.2672e-01, -4.5049e-01, -1.0000e+12, -1.0000e+12, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [-2.5221e-01, -6.1589e-02, -2.7533e-02, -1.0000e+12, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [-3.0623e-01, -9.9672e-03,  2.0290e-01, -3.0623e-01, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [-4.3324e-02, -1.9837e-01,  4.2463e-02, -4.3324e-02, -5.6604e-03,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 1.2510e-01,  4.5870e-03,  2.9071e-01,  1.2510e-01,  1.9759e-01,\n",
            "           -7.3271e-03, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [-4.3668e-01,  2.3874e-02,  2.8794e-02, -4.3668e-01,  1.9969e-01,\n",
            "           -1.8814e-01, -1.1984e-01, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [-4.3324e-02, -1.9837e-01,  4.2463e-02, -4.3324e-02, -5.6604e-03,\n",
            "           -4.3769e-02, -2.9458e-03, -5.6604e-03, -1.0000e+12, -1.0000e+12],\n",
            "          [-2.2077e-01, -1.5783e-02, -3.6967e-02, -2.2077e-01,  5.3954e-02,\n",
            "           -7.8426e-02, -1.2965e-01,  5.3954e-02,  2.9863e-02, -1.0000e+12],\n",
            "          [-1.4709e-01, -4.2518e-01, -1.5949e-01, -1.4709e-01, -1.9627e-01,\n",
            "           -5.4160e-02, -2.8361e-01, -1.9627e-01, -1.6527e-01, -1.0000e+12]],\n",
            "\n",
            "         [[ 3.9022e-01, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 3.6433e-01,  1.3598e-01, -1.0000e+12, -1.0000e+12, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [-4.4998e-03, -1.6452e-01, -5.6289e-02, -1.0000e+12, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 3.9022e-01,  9.9860e-02,  5.2755e-01,  3.9022e-01, -1.0000e+12,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [-9.5720e-02, -1.5488e-01, -1.7141e-01, -9.5720e-02, -7.9057e-02,\n",
            "           -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 3.4192e-01,  3.6776e-01,  5.1806e-01,  3.4192e-01,  1.0030e-01,\n",
            "           -1.9652e-01, -1.0000e+12, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [ 3.1423e-01, -2.9343e-02,  2.5816e-01,  3.1423e-01, -1.6202e-01,\n",
            "           -8.7928e-02,  4.6982e-01, -1.0000e+12, -1.0000e+12, -1.0000e+12],\n",
            "          [-9.5720e-02, -1.5488e-01, -1.7141e-01, -9.5720e-02, -7.9057e-02,\n",
            "           -2.4936e-02, -2.3125e-01, -7.9057e-02, -1.0000e+12, -1.0000e+12],\n",
            "          [ 2.7664e-01,  1.8561e-01,  2.0043e-01,  2.7664e-01,  4.2680e-02,\n",
            "            4.8245e-02,  3.3192e-01,  4.2680e-02,  1.5735e-01, -1.0000e+12],\n",
            "          [ 5.2308e-01,  1.0651e-01,  1.7753e-01,  5.2308e-01, -4.5541e-02,\n",
            "            3.9907e-01,  3.0748e-01, -4.5541e-02,  2.0371e-01, -1.0000e+12]]]],\n",
            "       grad_fn=<MaskedFillBackward0>)\n",
            "torch.Size([5, 2, 10, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9157psbw86k"
      },
      "source": [
        "`-1 * inf` is gonna be `0` after softmax applied"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rWxmCEOxFuI",
        "outputId": "706a4623-73f8-441a-ab4b-c2ab444ddb51"
      },
      "source": [
        "attn_dists = F.softmax(masked_attn_scores, dim = -1)  # (B, num_heads, L, d_k)\n",
        "\n",
        "print(attn_dists)\n",
        "print(attn_dists.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.6176, 0.3824, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.2217, 0.4678, 0.3105, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.2703, 0.2962, 0.2408, 0.1926, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.1567, 0.2438, 0.1759, 0.2051, 0.2186, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.2027, 0.1466, 0.1785, 0.1596, 0.1583, 0.1542, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.1047, 0.1515, 0.1388, 0.1603, 0.1381, 0.1635, 0.1432, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.1623, 0.1005, 0.1397, 0.1178, 0.1166, 0.1160, 0.1468, 0.1005,\n",
            "           0.0000, 0.0000],\n",
            "          [0.1278, 0.1197, 0.1210, 0.1106, 0.1346, 0.1346, 0.1319, 0.1197,\n",
            "           0.0000, 0.0000],\n",
            "          [0.1278, 0.1197, 0.1210, 0.1106, 0.1346, 0.1346, 0.1319, 0.1197,\n",
            "           0.0000, 0.0000]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.6516, 0.3484, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.3009, 0.3674, 0.3317, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.3132, 0.1155, 0.3170, 0.2543, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.1653, 0.2030, 0.2201, 0.2008, 0.2107, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.1182, 0.2403, 0.1476, 0.1561, 0.1675, 0.1704, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.1351, 0.1499, 0.1421, 0.1419, 0.1429, 0.1410, 0.1472, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.1481, 0.0792, 0.1719, 0.1590, 0.1268, 0.0790, 0.1570, 0.0792,\n",
            "           0.0000, 0.0000],\n",
            "          [0.1085, 0.1180, 0.1502, 0.1328, 0.1166, 0.0916, 0.1644, 0.1180,\n",
            "           0.0000, 0.0000],\n",
            "          [0.1085, 0.1180, 0.1502, 0.1328, 0.1166, 0.0916, 0.1644, 0.1180,\n",
            "           0.0000, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.5812, 0.4188, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.3459, 0.3244, 0.3297, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.2929, 0.2246, 0.2471, 0.2355, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.1601, 0.1924, 0.2454, 0.0975, 0.3046, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.1769, 0.2224, 0.1756, 0.2546, 0.1705, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.1769, 0.2224, 0.1756, 0.2546, 0.1705, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.1769, 0.2224, 0.1756, 0.2546, 0.1705, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.1769, 0.2224, 0.1756, 0.2546, 0.1705, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.1769, 0.2224, 0.1756, 0.2546, 0.1705, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.4803, 0.5197, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.3449, 0.3519, 0.3031, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.2976, 0.2231, 0.2501, 0.2292, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.3024, 0.2183, 0.1438, 0.2539, 0.0816, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.2041, 0.2476, 0.2221, 0.1994, 0.1268, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.2041, 0.2476, 0.2221, 0.1994, 0.1268, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.2041, 0.2476, 0.2221, 0.1994, 0.1268, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.2041, 0.2476, 0.2221, 0.1994, 0.1268, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.2041, 0.2476, 0.2221, 0.1994, 0.1268, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.6430, 0.3570, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.3592, 0.2930, 0.3478, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.2472, 0.1588, 0.3742, 0.2198, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.1851, 0.1639, 0.2383, 0.1706, 0.2422, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.1443, 0.1380, 0.2065, 0.1611, 0.1726, 0.1776, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.0687, 0.1077, 0.2218, 0.0956, 0.1534, 0.1210, 0.2318, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.0986, 0.1168, 0.1653, 0.1222, 0.1397, 0.1090, 0.1469, 0.1016,\n",
            "           0.0000, 0.0000],\n",
            "          [0.0872, 0.0849, 0.1428, 0.0870, 0.1271, 0.1088, 0.1453, 0.1050,\n",
            "           0.1121, 0.0000],\n",
            "          [0.0976, 0.0834, 0.1084, 0.0981, 0.1023, 0.0989, 0.0975, 0.0871,\n",
            "           0.1165, 0.1103]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.7090, 0.2910, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.4064, 0.3647, 0.2289, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.3770, 0.2132, 0.1891, 0.2207, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.1735, 0.1946, 0.2196, 0.1963, 0.2160, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.2099, 0.1034, 0.1501, 0.1041, 0.1325, 0.3002, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.1171, 0.1023, 0.1956, 0.0995, 0.1560, 0.1434, 0.1863, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.1656, 0.0697, 0.0881, 0.0728, 0.0786, 0.1944, 0.1452, 0.1855,\n",
            "           0.0000, 0.0000],\n",
            "          [0.0947, 0.1168, 0.1229, 0.1083, 0.1177, 0.0985, 0.1115, 0.1165,\n",
            "           0.1131, 0.0000],\n",
            "          [0.0947, 0.0789, 0.1061, 0.0748, 0.0946, 0.1189, 0.1328, 0.1369,\n",
            "           0.0764, 0.0859]]],\n",
            "\n",
            "\n",
            "        [[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.4834, 0.5166, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.3066, 0.3324, 0.3610, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.2161, 0.3212, 0.2040, 0.2587, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.3035, 0.2288, 0.2418, 0.2258, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.3035, 0.2288, 0.2418, 0.2258, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.3035, 0.2288, 0.2418, 0.2258, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.3035, 0.2288, 0.2418, 0.2258, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.3035, 0.2288, 0.2418, 0.2258, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.3035, 0.2288, 0.2418, 0.2258, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.6169, 0.3831, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.3962, 0.3001, 0.3037, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.2681, 0.2486, 0.2460, 0.2373, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.3186, 0.2008, 0.2065, 0.2741, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.3186, 0.2008, 0.2065, 0.2741, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.3186, 0.2008, 0.2065, 0.2741, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.3186, 0.2008, 0.2065, 0.2741, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.3186, 0.2008, 0.2065, 0.2741, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.3186, 0.2008, 0.2065, 0.2741, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000]]],\n",
            "\n",
            "\n",
            "        [[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.4561, 0.5439, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.2889, 0.3495, 0.3616, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.1997, 0.2685, 0.3322, 0.1997, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.2006, 0.1718, 0.2186, 0.2006, 0.2083, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.1662, 0.1473, 0.1961, 0.1662, 0.1787, 0.1456, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.1029, 0.1630, 0.1638, 0.1029, 0.1944, 0.1319, 0.1412, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.1240, 0.1062, 0.1351, 0.1240, 0.1288, 0.1240, 0.1291, 0.1288,\n",
            "           0.0000, 0.0000],\n",
            "          [0.0944, 0.1159, 0.1134, 0.0944, 0.1242, 0.1088, 0.1034, 0.1242,\n",
            "           0.1213, 0.0000],\n",
            "          [0.1163, 0.0880, 0.1148, 0.1163, 0.1107, 0.1276, 0.1014, 0.1107,\n",
            "           0.1142, 0.0000]],\n",
            "\n",
            "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.5568, 0.4432, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.3569, 0.3042, 0.3389, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.2567, 0.1920, 0.2945, 0.2567, 0.0000, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.2046, 0.1929, 0.1897, 0.2046, 0.2081, 0.0000, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.1790, 0.1836, 0.2134, 0.1790, 0.1405, 0.1045, 0.0000, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.1636, 0.1160, 0.1547, 0.1636, 0.1016, 0.1094, 0.1911, 0.0000,\n",
            "           0.0000, 0.0000],\n",
            "          [0.1274, 0.1201, 0.1181, 0.1274, 0.1295, 0.1367, 0.1112, 0.1295,\n",
            "           0.0000, 0.0000],\n",
            "          [0.1225, 0.1119, 0.1135, 0.1225, 0.0970, 0.0975, 0.1295, 0.0970,\n",
            "           0.1087, 0.0000],\n",
            "          [0.1446, 0.0953, 0.1023, 0.1446, 0.0819, 0.1277, 0.1166, 0.0819,\n",
            "           0.1051, 0.0000]]]], grad_fn=<SoftmaxBackward>)\n",
            "torch.Size([5, 2, 10, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q1D8NG8YxOZy",
        "outputId": "3ecb6aa0-41d6-4a9c-9be3-a8de48d346a9"
      },
      "source": [
        "attn_values = torch.matmul(attn_dists, v) # (B, num_heads, L, d_k)\n",
        "\n",
        "print(attn_values.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 2, 10, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8-XwZmsxbhW"
      },
      "source": [
        "## the whole code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-OidsFSxejD"
      },
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MultiHeadAttention, self).__init__()\n",
        "\n",
        "    # Q, K, V learnerable matrices\n",
        "    self.w_q = nn.Linear(d_model, d_model)\n",
        "    self.w_k = nn.Linear(d_model, d_model)\n",
        "    self.w_v = nn.Linear(d_model, d_model)\n",
        "\n",
        "    # Linaer transformation for concatenated outputs\n",
        "    self.w_0 = nn.Linear(d_model, d_model)\n",
        "\n",
        "  def forward(self, q, k, v, mask = None):\n",
        "    batch_size = q.shape[0]\n",
        "\n",
        "    q = self.w_q(q) # (B, L, d_model)\n",
        "    k = self.w_k(k) # (B, L, d_model)\n",
        "    v = self.w_v(v) # (B, L, d_model)\n",
        "\n",
        "    q = q.view(batch_size, -1, num_heads, d_k)  # (B, L, num_heads, d_k)\n",
        "    k = k.view(batch_size, -1, num_heads, d_k)  # (B, L, num_heads, d_k)\n",
        "    v = v.view(batch_size, -1, num_heads, d_k)  # (B, L, num_heads, d_k)\n",
        "\n",
        "    q = q.transpose(1, 2) # (B, num_heads, L, d_k)\n",
        "    k = k.transpose(1, 2) # (B, num_heads, L, d_k)\n",
        "    v = v.transpose(1, 2) # (B, num_heads, L, d_k)\n",
        "\n",
        "    attn_values = self.self_attention(q, k, v, mask = mask) # (B, num_heads, L, d_k)\n",
        "    attn_values = attn_values.transpose(1, 2).contiguous().view(batch_size, -1, d_model) # (B, L, num_heads, d_k) => (B, L, d_model)\n",
        "\n",
        "    return self.w_0(attn_values)\n",
        "  \n",
        "  def self_attention(self, q, k, v, mask = None):\n",
        "    attn_scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k) # (B, num_heads, L, L)\n",
        "\n",
        "    if mask is not None:\n",
        "      mask = mask.unsqueeze(1)  # (B, 1, L, L) or (B, 1, 1, L)\n",
        "      attn_scores = attn_scores.masked_fill_(mask == False, -1*inf)\n",
        "    \n",
        "    attn_dists = F.softmax(attn_scores, dim = -1) # (B, num_heads, L, L)\n",
        "    attn_values = torch.matmul(attn_dists, v)     # (B, num_heads, L, d_k)\n",
        "\n",
        "    return attn_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yBruUiemzx2Y"
      },
      "source": [
        "multihead_attn = MultiHeadAttention()\n",
        "\n",
        "outputs = multihead_attn(batch_emb, batch_emb, batch_emb, mask = mask)  # (B, L, d_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z7B2dRWVz-ry",
        "outputId": "7e5312d5-4d07-4b04-e51d-700c0c8797e7"
      },
      "source": [
        "print(outputs)\n",
        "print(outputs.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[ 1.0917e+00,  2.8661e-02, -3.0873e-01,  3.3833e-01, -4.0447e-01,\n",
            "           2.5567e-01, -3.2935e-01,  4.2472e-01],\n",
            "         [ 1.1372e-01, -3.3286e-02,  3.8443e-01, -5.6257e-02,  3.1793e-02,\n",
            "           4.5371e-01,  1.1532e-01, -2.6525e-02],\n",
            "         [ 5.1314e-01, -1.1402e-01,  7.1595e-02,  2.2340e-01, -2.2535e-01,\n",
            "           3.4830e-01,  1.8477e-02,  1.8242e-01],\n",
            "         [ 3.4497e-01,  1.1171e-01,  8.5337e-03,  2.3904e-01, -2.2966e-02,\n",
            "           2.0238e-01,  2.6598e-01,  2.4121e-01],\n",
            "         [ 3.9921e-01, -3.2567e-02,  8.6769e-02,  2.3958e-01, -7.2909e-02,\n",
            "           3.1351e-01,  2.0750e-01,  1.2090e-01],\n",
            "         [ 2.5025e-01, -7.7398e-03,  2.3225e-01,  1.6333e-01,  2.7752e-03,\n",
            "           3.4592e-01,  2.4483e-01,  6.9345e-02],\n",
            "         [ 3.1394e-01, -1.8729e-02,  1.6940e-01,  1.6482e-01, -9.5959e-02,\n",
            "           2.9457e-01,  1.2831e-01,  1.8098e-01],\n",
            "         [ 1.3698e-01,  1.4190e-03,  2.8889e-01,  9.6515e-02,  2.6682e-02,\n",
            "           3.4300e-01,  2.4716e-01,  6.7828e-02],\n",
            "         [ 8.5969e-02, -5.6823e-02,  3.6592e-01,  4.3094e-02,  3.5186e-02,\n",
            "           3.8665e-01,  2.2729e-01,  1.6851e-03],\n",
            "         [ 8.5969e-02, -5.6823e-02,  3.6592e-01,  4.3094e-02,  3.5186e-02,\n",
            "           3.8665e-01,  2.2729e-01,  1.6851e-03]],\n",
            "\n",
            "        [[-4.4637e-01,  3.1336e-01,  3.1792e-01, -2.2979e-01,  3.5639e-01,\n",
            "          -1.9826e-01,  1.5271e-01,  3.2671e-01],\n",
            "         [ 1.4062e-01,  2.0738e-01,  7.6701e-02,  6.7233e-02,  7.4865e-02,\n",
            "          -9.9479e-03,  1.2207e-01,  3.5317e-01],\n",
            "         [ 3.2414e-01,  1.8859e-01, -5.7123e-02,  1.9584e-01, -3.3404e-02,\n",
            "          -2.0401e-02,  1.4789e-01,  4.3495e-01],\n",
            "         [ 2.0596e-01,  1.1981e-01,  1.7322e-01,  1.7649e-01, -2.3098e-02,\n",
            "           4.7919e-02,  1.8825e-01,  3.7399e-01],\n",
            "         [ 3.6325e-01, -7.5138e-02,  3.4241e-01, -3.2809e-02, -8.9795e-02,\n",
            "           4.2836e-01, -1.3237e-01,  5.3097e-02],\n",
            "         [ 2.4194e-01, -2.4002e-02,  3.2461e-01,  6.5546e-02, -3.2958e-02,\n",
            "           2.6147e-01,  6.1363e-02,  1.5446e-01],\n",
            "         [ 2.4194e-01, -2.4002e-02,  3.2461e-01,  6.5546e-02, -3.2958e-02,\n",
            "           2.6147e-01,  6.1363e-02,  1.5446e-01],\n",
            "         [ 2.4194e-01, -2.4002e-02,  3.2461e-01,  6.5546e-02, -3.2958e-02,\n",
            "           2.6147e-01,  6.1363e-02,  1.5446e-01],\n",
            "         [ 2.4194e-01, -2.4002e-02,  3.2461e-01,  6.5546e-02, -3.2958e-02,\n",
            "           2.6147e-01,  6.1363e-02,  1.5446e-01],\n",
            "         [ 2.4194e-01, -2.4002e-02,  3.2461e-01,  6.5546e-02, -3.2958e-02,\n",
            "           2.6147e-01,  6.1363e-02,  1.5446e-01]],\n",
            "\n",
            "        [[ 5.7061e-01,  2.5587e-01, -5.7865e-01,  1.4980e-01, -9.4849e-02,\n",
            "          -2.6843e-01, -3.2164e-02,  6.1942e-01],\n",
            "         [ 1.6312e-01,  2.9468e-01, -4.1364e-01,  1.1082e-01,  9.0551e-02,\n",
            "          -3.9938e-01,  2.4739e-01,  6.0114e-01],\n",
            "         [-1.5703e-01,  2.0961e-01,  3.0065e-02,  1.6583e-02,  1.6475e-01,\n",
            "          -2.7033e-01,  4.0017e-01,  4.7173e-01],\n",
            "         [-3.7348e-02,  2.3104e-01, -1.0158e-01,  6.6269e-02,  1.3172e-01,\n",
            "          -2.7116e-01,  3.6393e-01,  4.9277e-01],\n",
            "         [-6.1865e-02,  2.6414e-01, -6.7385e-03,  2.4661e-02,  1.2795e-01,\n",
            "          -2.5377e-01,  3.2523e-01,  5.2296e-01],\n",
            "         [ 2.0391e-01,  2.3438e-01, -2.3120e-01,  1.6010e-01,  5.0593e-02,\n",
            "          -2.4625e-01,  2.9152e-01,  5.2403e-01],\n",
            "         [ 2.9366e-01,  1.4298e-01, -1.6383e-01,  2.3171e-01, -2.1763e-02,\n",
            "          -1.6997e-01,  2.8162e-01,  4.8817e-01],\n",
            "         [ 2.9346e-01,  1.7218e-01, -2.0598e-01,  1.9193e-01,  8.7095e-03,\n",
            "          -1.5903e-01,  2.3806e-01,  4.5850e-01],\n",
            "         [ 2.3902e-01,  1.0816e-01, -6.3309e-02,  2.2613e-01, -1.9834e-02,\n",
            "          -9.8628e-02,  2.9367e-01,  4.3166e-01],\n",
            "         [ 2.7720e-01,  1.7540e-01, -1.3021e-01,  2.1335e-01, -6.4863e-04,\n",
            "          -1.0053e-01,  2.5266e-01,  4.4503e-01]],\n",
            "\n",
            "        [[ 4.5463e-01, -2.4022e-02, -1.3339e-01,  8.7795e-02, -1.2177e-01,\n",
            "          -2.4464e-02,  8.4966e-02,  3.7106e-01],\n",
            "         [ 1.0548e-01, -6.8637e-02,  3.5718e-01, -3.7847e-02,  4.2566e-02,\n",
            "           3.8525e-01,  8.7367e-02, -2.6913e-02],\n",
            "         [-2.7741e-02,  7.0003e-02,  4.9166e-01, -2.2476e-01,  1.1576e-01,\n",
            "           4.9011e-01, -3.4492e-02, -5.3014e-02],\n",
            "         [ 2.4112e-01,  1.8914e-02,  2.3717e-01,  5.6716e-02, -3.5044e-02,\n",
            "           3.6946e-01,  5.2569e-02,  9.9936e-02],\n",
            "         [ 1.8800e-01,  5.0376e-02,  2.6750e-01,  1.2093e-02, -1.1172e-03,\n",
            "           3.5839e-01,  8.0040e-02,  1.0736e-01],\n",
            "         [ 1.8800e-01,  5.0376e-02,  2.6750e-01,  1.2093e-02, -1.1172e-03,\n",
            "           3.5839e-01,  8.0040e-02,  1.0736e-01],\n",
            "         [ 1.8800e-01,  5.0376e-02,  2.6750e-01,  1.2093e-02, -1.1172e-03,\n",
            "           3.5839e-01,  8.0040e-02,  1.0736e-01],\n",
            "         [ 1.8800e-01,  5.0376e-02,  2.6750e-01,  1.2093e-02, -1.1172e-03,\n",
            "           3.5839e-01,  8.0040e-02,  1.0736e-01],\n",
            "         [ 1.8800e-01,  5.0376e-02,  2.6750e-01,  1.2093e-02, -1.1172e-03,\n",
            "           3.5839e-01,  8.0040e-02,  1.0736e-01],\n",
            "         [ 1.8800e-01,  5.0376e-02,  2.6750e-01,  1.2093e-02, -1.1172e-03,\n",
            "           3.5839e-01,  8.0040e-02,  1.0736e-01]],\n",
            "\n",
            "        [[ 1.3340e-02,  6.4736e-01, -5.3928e-01, -4.4362e-01,  2.0825e-01,\n",
            "          -5.6453e-01, -2.6462e-01,  7.9582e-01],\n",
            "         [-8.2867e-03,  4.2413e-01, -3.2738e-01, -1.5936e-01,  1.6939e-01,\n",
            "          -3.8378e-01,  9.4045e-02,  6.1298e-01],\n",
            "         [ 1.8098e-01,  3.4707e-01, -3.0086e-01,  9.7531e-03,  5.2826e-02,\n",
            "          -2.7956e-01,  1.1546e-01,  6.0554e-01],\n",
            "         [ 1.3033e-01,  4.1010e-01, -3.5391e-01, -8.6948e-02,  9.2565e-02,\n",
            "          -3.4196e-01,  5.1148e-02,  6.4109e-01],\n",
            "         [ 1.2126e-01,  3.7155e-01, -2.1095e-01, -5.7289e-02,  7.4984e-02,\n",
            "          -2.4092e-01,  7.8634e-02,  5.8787e-01],\n",
            "         [-6.4076e-02,  3.9097e-01, -1.1204e-01, -1.9365e-01,  1.5003e-01,\n",
            "          -2.5912e-01,  9.2117e-02,  5.6230e-01],\n",
            "         [ 7.7630e-02,  3.8446e-01, -2.1375e-01, -8.6979e-02,  9.2736e-02,\n",
            "          -2.6273e-01,  8.5931e-02,  5.9601e-01],\n",
            "         [ 5.4349e-02,  3.3031e-01, -1.1801e-01, -8.5894e-02,  8.2493e-02,\n",
            "          -1.9622e-01,  1.0759e-01,  5.4161e-01],\n",
            "         [ 6.2996e-02,  3.3555e-01, -1.2304e-01, -5.8827e-02,  8.4694e-02,\n",
            "          -2.0004e-01,  1.2922e-01,  5.4521e-01],\n",
            "         [ 6.0510e-02,  3.2304e-01, -1.0410e-01, -4.2702e-02,  8.2517e-02,\n",
            "          -1.8718e-01,  1.5042e-01,  5.3449e-01]]], grad_fn=<AddBackward0>)\n",
            "torch.Size([5, 10, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3w_h_aV0LKt"
      },
      "source": [
        "## Encode-Decode Attetion\n",
        "\n",
        "only differ in Query, key, value\n",
        "\n",
        "the implementation is same\n",
        "\n",
        "let's implement the batch which is an input for decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZESrDnK0jCR",
        "outputId": "437a4955-f4e3-4a38-ae37-f97e6ba24f91"
      },
      "source": [
        "trg_data = [\n",
        "  [33, 11, 49, 10],\n",
        "  [88, 34, 5, 29, 99, 45, 11, 25],\n",
        "  [67, 25, 15, 90, 54, 4, 92, 10, 46, 20, 88 ,19],\n",
        "  [16, 58, 91, 47, 12, 5, 8],\n",
        "  [71, 63, 62, 7, 9, 11, 55, 91, 32, 48]\n",
        "]\n",
        "\n",
        "trg_data, trg_max_len = padding(trg_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 5/5 [00:00<00:00, 2959.99it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Maximum sequence length: 12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yygKzpf0nCk",
        "outputId": "fcc944c3-4bff-4598-e6ec-e8b045068d72"
      },
      "source": [
        "# S_L: source maximum sequence length, T_L: target maximum sequence length\n",
        "src_batch = batch # (B, S_L)\n",
        "trg_batch = torch.LongTensor(trg_data)  # (B, T_L)\n",
        "\n",
        "print(src_batch.shape)\n",
        "print(trg_batch.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 10])\n",
            "torch.Size([5, 12])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFT4UvTZ0_us",
        "outputId": "3e5137ca-45a7-4922-c195-ce2189e4caf4"
      },
      "source": [
        "src_emb = embedding(src_batch)  # (B, S_L, d_w)\n",
        "trg_emb = embedding(trg_batch)  # (B, S_L, d_w)\n",
        "\n",
        "print(src_emb.shape)\n",
        "print(trg_emb.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 10, 8])\n",
            "torch.Size([5, 12, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYgFOkpu1Qoz"
      },
      "source": [
        "suppose that\n",
        "\n",
        "- `src_emb` is the output of encoder\n",
        "- `trg_emb` is the output of masked multi-head attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aysj5eZ81jvO",
        "outputId": "e47af658-804d-4c01-ab5f-218a9275d6e8"
      },
      "source": [
        "q = w_q(trg_emb)  # (B, T_L, d_model)\n",
        "k = w_k(trg_emb)  # (B, T_L, d_model)\n",
        "v = w_v(trg_emb)  # (B, T_L, d_model)\n",
        "\n",
        "batch_size = q.shape[0]\n",
        "d_k = d_model // num_heads\n",
        "\n",
        "q = q.view(batch_size, -1, num_heads, d_k)  # (B, T_L, num_heads, d_k)\n",
        "k = k.view(batch_size, -1, num_heads, d_k)  # (B, T_L, num_heads, d_k)\n",
        "v = v.view(batch_size, -1, num_heads, d_k)  # (B, T_L, num_heads, d_k)\n",
        "\n",
        "q = q.transpose(1, 2) # (B, num_heads, T_L, d_k)\n",
        "k = k.transpose(1, 2) # (B, num_heads, T_L, d_k)\n",
        "v = v.transpose(1, 2) # (B, num_heads, T_L, d_k)\n",
        "\n",
        "print(q.shape)\n",
        "print(k.shape)\n",
        "print(v.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 2, 12, 4])\n",
            "torch.Size([5, 2, 12, 4])\n",
            "torch.Size([5, 2, 12, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCiyzbH72FHK",
        "outputId": "56e56e5e-b1be-4780-9ec1-5bd20d64bc9e"
      },
      "source": [
        "attn_scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k) # (B, num_heads, T_L, S_L)\n",
        "attn_dists = F.softmax(attn_scores, dim = -1) # (B, num_heads, T_L, S_L)\n",
        "\n",
        "print(attn_dists.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 2, 12, 12])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-OM9Mj52YUF",
        "outputId": "ccc6f133-0703-4322-a68e-149a9e2a952b"
      },
      "source": [
        "attn_values = torch.matmul(attn_dists, v) # (B, num_heads, T_L, d_k)\n",
        "\n",
        "print(attn_values.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 2, 12, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2M3j4H22jLT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}