{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM and GRU.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H_c6z6xOMLxu"
      },
      "source": [
        "# LSTM, GRU\n",
        "1. 기존 RNN과 다른 부분에 대해서 배우자\n",
        "2. 이전 실습에 이어 다양한 적용법을 배우자"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCA0L9mKMgeF"
      },
      "source": [
        "## 필요 패키지 import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ujPjIhZzMjNX"
      },
      "source": [
        "from tqdm import tqdm\n",
        "from torch import nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFzuKnRbMun4"
      },
      "source": [
        "## 데이터 전처리\n",
        "아래의 sample data를 확인\n",
        "이전 실습과 동일"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLjINsUQM2az"
      },
      "source": [
        "vocab_size = 100\n",
        "pad_id = 0\n",
        "\n",
        "data = [\n",
        "  [85,14,80,34,99,20,31,65,53,86,3,58,30,4,11,6,50,71,74,13],\n",
        "  [62,76,79,66,32],\n",
        "  [93,77,16,67,46,74,24,70],\n",
        "  [19,83,88,22,57,40,75,82,4,46],\n",
        "  [70,28,30,24,76,84,92,76,77,51,7,20,82,94,57],\n",
        "  [58,13,40,61,88,18,92,89,8,14,61,67,49,59,45,12,47,5],\n",
        "  [22,5,21,84,39,6,9,84,36,59,32,30,69,70,82,56,1],\n",
        "  [94,21,79,24,3,86],\n",
        "  [80,80,33,63,34,63],\n",
        "  [87,32,79,65,2,96,43,80,85,20,41,52,95,50,35,96,24,80]\n",
        "]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JOebtZUM7Mn",
        "outputId": "10996d2b-f83d-45f7-cab8-d6ef97c8f6f2"
      },
      "source": [
        "max_len = len(max(data, key = len))\n",
        "print(f\"Maximum sequence length: {max_len}\")\n",
        "\n",
        "valid_lens = []\n",
        "for i, seq in enumerate(tqdm(data)):\n",
        "  valid_lens.append(len(seq))\n",
        "  if len(seq)<max_len:\n",
        "    data[i] = seq + [pad_id] * (max_len-len(seq))\n",
        "    "
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 5636.75it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Maximum sequence length: 20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1UTvT6kNaf1",
        "outputId": "398d18e9-a0b1-4d6f-9dc9-7e80c112445d"
      },
      "source": [
        "batch = torch.LongTensor(data)\n",
        "batch_lens = torch.LongTensor(valid_lens)\n",
        "\n",
        "batch_lens, sorted_idx = batch_lens.sort(descending = True)\n",
        "batch = batch[sorted_idx]\n",
        "\n",
        "print(batch)\n",
        "print(batch_lens)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[85, 14, 80, 34, 99, 20, 31, 65, 53, 86,  3, 58, 30,  4, 11,  6, 50, 71,\n",
            "         74, 13],\n",
            "        [58, 13, 40, 61, 88, 18, 92, 89,  8, 14, 61, 67, 49, 59, 45, 12, 47,  5,\n",
            "          0,  0],\n",
            "        [87, 32, 79, 65,  2, 96, 43, 80, 85, 20, 41, 52, 95, 50, 35, 96, 24, 80,\n",
            "          0,  0],\n",
            "        [22,  5, 21, 84, 39,  6,  9, 84, 36, 59, 32, 30, 69, 70, 82, 56,  1,  0,\n",
            "          0,  0],\n",
            "        [70, 28, 30, 24, 76, 84, 92, 76, 77, 51,  7, 20, 82, 94, 57,  0,  0,  0,\n",
            "          0,  0],\n",
            "        [19, 83, 88, 22, 57, 40, 75, 82,  4, 46,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0],\n",
            "        [93, 77, 16, 67, 46, 74, 24, 70,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0],\n",
            "        [94, 21, 79, 24,  3, 86,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0],\n",
            "        [80, 80, 33, 63, 34, 63,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0],\n",
            "        [62, 76, 79, 66, 32,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0]])\n",
            "tensor([20, 18, 18, 17, 15, 10,  8,  6,  6,  5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBHqU8sRNwPA"
      },
      "source": [
        "## LSTM 사용\n",
        "LSTM에선 cell state가 추가됩니다.\n",
        "cell state의 shape는 hidden state의 그것과 동일합니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NfEhR0kN_qP"
      },
      "source": [
        "embedding_size = 256\n",
        "hidden_size = 512\n",
        "num_layers = 1\n",
        "num_dirs = 1\n",
        "\n",
        "embedding = nn.Embedding(vocab_size, embedding_size)\n",
        "lstm = nn.LSTM(\n",
        "    input_size = embedding_size, \n",
        "    hidden_size = hidden_size,\n",
        "    num_layers = num_layers,\n",
        "    bidirectional = True if num_dirs>1 else False\n",
        ")\n",
        "\n",
        "h_0 = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size))\n",
        "c_0 = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "us62KGFIOQkV",
        "outputId": "5bde0f56-4356-4d58-cf7c-777a76d5128e"
      },
      "source": [
        "batch_emb = embedding(batch)\n",
        "\n",
        "packed_batch = pack_padded_sequence(batch_emb.transpose(0, 1), batch_lens)\n",
        "\n",
        "packed_outputs, (h_n, c_n) = lstm(packed_batch, (h_0, c_0))\n",
        "print(packed_outputs)\n",
        "print(packed_outputs[0].shape)\n",
        "print(h_n.shape)\n",
        "print(c_n.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PackedSequence(data=tensor([[ 0.1140, -0.0754,  0.0414,  ...,  0.0184, -0.1301,  0.1099],\n",
            "        [-0.0372, -0.0944,  0.1062,  ...,  0.0229,  0.0084,  0.0609],\n",
            "        [-0.0436,  0.1051,  0.1014,  ..., -0.0444,  0.2490, -0.1016],\n",
            "        ...,\n",
            "        [ 0.0047,  0.1545,  0.2151,  ..., -0.1920,  0.0463,  0.0955],\n",
            "        [ 0.1495, -0.0825, -0.1940,  ..., -0.0950,  0.0918,  0.0778],\n",
            "        [ 0.1905, -0.0985, -0.1822,  ..., -0.0274,  0.0376,  0.1549]],\n",
            "       grad_fn=<CatBackward>), batch_sizes=tensor([10, 10, 10, 10, 10,  9,  7,  7,  6,  6,  5,  5,  5,  5,  5,  4,  4,  3,\n",
            "         1,  1]), sorted_indices=None, unsorted_indices=None)\n",
            "torch.Size([123, 512])\n",
            "torch.Size([1, 10, 512])\n",
            "torch.Size([1, 10, 512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Izw51AMXY7Z",
        "outputId": "dd62f7eb-9569-48d9-d0bb-83748e5da408"
      },
      "source": [
        "outputs, output_lens = pad_packed_sequence(packed_outputs)\n",
        "print(outputs.shape)\n",
        "print(output_lens)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([20, 10, 512])\n",
            "tensor([20, 18, 18, 17, 15, 10,  8,  6,  6,  5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cilglA8BXQPb"
      },
      "source": [
        "## GRU 사용\n",
        "GRU는 cell state가 없이 RNN과 동일하게 사용 가능\n",
        "GRU를 이용하여 LM task를 수행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7E4JiT1kXrvC"
      },
      "source": [
        "gru = nn.GRU(\n",
        "    input_size = embedding_size, \n",
        "    hidden_size = hidden_size,\n",
        "    num_layers = num_layers,\n",
        "    bidirectional = True if num_dirs>1 else False\n",
        ")"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ao3bwz1eX8-j"
      },
      "source": [
        "output_layer = nn.Linear(hidden_size, vocab_size)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kr6igcchYxhe"
      },
      "source": [
        "input_id = batch.transpose(0, 1)[0,:]\n",
        "hidden = torch.zeros((num_layers*num_dirs, batch.shape[0], hidden_size))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfQzY1IXYLO5",
        "outputId": "cc23cae6-3bcc-4175-c856-c25eae8c6949"
      },
      "source": [
        "for t in range(max_len):\n",
        "  input_emb = embedding(input_id).unsqueeze(0)\n",
        "  output, hidden = gru(input_emb, hidden)\n",
        "\n",
        "  output = output_layer(output)\n",
        "  probs, top_id = torch.max(output, dim = -1)\n",
        "\n",
        "  print(\"*\"*50)\n",
        "  print(f\"Time step: {t}\")\n",
        "  print(output.shape)\n",
        "  print(probs.shape)\n",
        "  print(top_id.shape)\n",
        "\n",
        "  input_id = top_id.squeeze(0)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "**************************************************\n",
            "Time step: 0\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 1\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 2\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 3\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 4\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 5\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 6\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 7\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 8\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 9\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 10\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 11\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 12\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 13\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 14\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 15\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 16\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 17\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 18\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n",
            "**************************************************\n",
            "Time step: 19\n",
            "torch.Size([1, 10, 100])\n",
            "torch.Size([1, 10])\n",
            "torch.Size([1, 10])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2d_qwdoSYurZ"
      },
      "source": [
        "## 양방향 및 여러 layer 사용\n",
        "이번엔 양방향 +2개 이상의 layer를 쓸 때 얻을 수 있는 결과에 대해 알아보자."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9F7LXcfGZY5A"
      },
      "source": [
        "num_layers = 2\n",
        "num_dirs = 2\n",
        "dropout = 0.1\n",
        "\n",
        "gru = nn.GRU(\n",
        "    input_size = embedding_size, \n",
        "    hidden_size = hidden_size,\n",
        "    num_layers = num_layers,\n",
        "    dropout = dropout,\n",
        "    bidirectional = True if num_dirs>1 else False\n",
        ")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8fF4inkZsPa"
      },
      "source": [
        "bidirectional이 되었고 layer의 개수가 2로 늘었기 때문에 hidden state의 shape도 `(4, B, d_h)`가 됨"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGkZDyCQZ4Q6",
        "outputId": "867c094e-10bf-4e86-b7be-146278d13207"
      },
      "source": [
        "batch_emb = embedding(batch)\n",
        "h_0 = torch.zeros((num_layers * num_dirs, batch.shape[0], hidden_size))\n",
        "\n",
        "packed_batch = pack_padded_sequence(batch_emb.transpose(0, 1), batch_lens)\n",
        "\n",
        "packed_outputs, h_n = gru(packed_batch, h_0)\n",
        "print(packed_outputs)\n",
        "print(packed_outputs[0].shape)\n",
        "print(h_n.shape)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PackedSequence(data=tensor([[-0.0616,  0.1419, -0.0419,  ...,  0.1286,  0.1644, -0.0350],\n",
            "        [-0.0446, -0.0617, -0.0475,  ...,  0.1917, -0.1740,  0.1693],\n",
            "        [ 0.0255, -0.0287, -0.0590,  ..., -0.0269, -0.0133, -0.0027],\n",
            "        ...,\n",
            "        [-0.0650,  0.0372,  0.0685,  ...,  0.0623,  0.0891,  0.0533],\n",
            "        [ 0.1509,  0.0227,  0.0581,  ...,  0.1506, -0.0588,  0.0192],\n",
            "        [ 0.1018, -0.0215,  0.1022,  ...,  0.1361, -0.0378, -0.0353]],\n",
            "       grad_fn=<CatBackward>), batch_sizes=tensor([10, 10, 10, 10, 10,  9,  7,  7,  6,  6,  5,  5,  5,  5,  5,  4,  4,  3,\n",
            "         1,  1]), sorted_indices=None, unsorted_indices=None)\n",
            "torch.Size([123, 1024])\n",
            "torch.Size([4, 10, 512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9I9Iu21aU0d",
        "outputId": "907b9985-bbea-4e81-89a8-312cda9c2181"
      },
      "source": [
        "outputs, output_lens = pad_packed_sequence(packed_outputs)\n",
        "\n",
        "print(outputs.shape)\n",
        "print(output_lens)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([20, 10, 1024])\n",
            "tensor([20, 18, 18, 17, 15, 10,  8,  6,  6,  5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xz-KEOQ_alX4",
        "outputId": "ecf114e0-862f-472b-d01a-91e21d18300e"
      },
      "source": [
        "batch_size = h_n.shape[1]\n",
        "print(h_n.view(num_layers, num_dirs, batch_size, hidden_size))\n",
        "print(h_n.view(num_layers, num_dirs, batch_size, hidden_size).shape)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[[ 0.4368, -0.3862, -0.0914,  ..., -0.4564, -0.0240, -0.0892],\n",
            "          [ 0.0985, -0.2560, -0.0031,  ..., -0.0098, -0.1318, -0.3166],\n",
            "          [ 0.2565, -0.3446,  0.0408,  ...,  0.1227,  0.2785,  0.0633],\n",
            "          ...,\n",
            "          [-0.2482,  0.0838, -0.2070,  ..., -0.2314,  0.0856,  0.2959],\n",
            "          [-0.3201,  0.0730,  0.0147,  ..., -0.6137,  0.0900, -0.0028],\n",
            "          [-0.0086, -0.0173, -0.1789,  ..., -0.3638,  0.1985,  0.1712]],\n",
            "\n",
            "         [[-0.1861,  0.2234,  0.5400,  ..., -0.0256, -0.0860,  0.2350],\n",
            "          [-0.0284, -0.0254,  0.0959,  ..., -0.1586,  0.0432,  0.3732],\n",
            "          [-0.0878,  0.3232, -0.0517,  ..., -0.2300, -0.3331,  0.3021],\n",
            "          ...,\n",
            "          [-0.5691,  0.1697,  0.4559,  ...,  0.0041, -0.0519,  0.1329],\n",
            "          [ 0.0297, -0.1635,  0.2470,  ..., -0.0777, -0.3214, -0.0565],\n",
            "          [-0.0101,  0.2400,  0.4176,  ..., -0.2866, -0.4759,  0.0602]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1018, -0.0215,  0.1022,  ...,  0.1940,  0.1381, -0.0305],\n",
            "          [ 0.1600,  0.1439, -0.0694,  ..., -0.0550, -0.1425,  0.1271],\n",
            "          [-0.0650,  0.0372,  0.0685,  ...,  0.3637,  0.1614,  0.2166],\n",
            "          ...,\n",
            "          [-0.1132, -0.0546,  0.0598,  ...,  0.3184,  0.0783, -0.0791],\n",
            "          [-0.0444,  0.1131, -0.0874,  ..., -0.0802,  0.0493,  0.1492],\n",
            "          [ 0.0303,  0.0919,  0.0742,  ..., -0.2005, -0.0921,  0.1309]],\n",
            "\n",
            "         [[ 0.0879,  0.1336,  0.1288,  ...,  0.1286,  0.1644, -0.0350],\n",
            "          [ 0.0590,  0.1953, -0.0883,  ...,  0.1917, -0.1740,  0.1693],\n",
            "          [-0.0804,  0.0459, -0.0699,  ..., -0.0269, -0.0133, -0.0027],\n",
            "          ...,\n",
            "          [ 0.2866, -0.0665, -0.0390,  ..., -0.0572,  0.0874, -0.1304],\n",
            "          [ 0.0191,  0.0515,  0.3054,  ...,  0.2031,  0.2177,  0.0587],\n",
            "          [ 0.0251,  0.0213,  0.0093,  ..., -0.0730,  0.1258,  0.1897]]]],\n",
            "       grad_fn=<ViewBackward>)\n",
            "torch.Size([2, 2, 10, 512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "30h7CAUCa46P"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}