{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "basic rnn.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Y1sZeAMZqd-"
      },
      "source": [
        "# RNN\n",
        "1. 주어진 데이터를 RNN에 넣을 수 있는 형태로 만든다.\n",
        "2. 기본적인 RNN 사용법 및 적용법을 익힌다.\n",
        "3. packedsequence의 필요성에 대해 배우고 적용법을 실습한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yw9egel4FhDx"
      },
      "source": [
        "## 필요 패키지 import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WMQ7TrhFktk"
      },
      "source": [
        "from tqdm import tqdm\n",
        "from torch import nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "import torch"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6X4ZC8atFxdj"
      },
      "source": [
        "## 데이터 전처리\n",
        "아래의 sample data 를 확인\n",
        "전체 단어 수와 pad token의 id도 아래와 같음."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tn2gg1EnF8ro"
      },
      "source": [
        "vocab_size = 100\n",
        "pad_id = 0\n",
        "\n",
        "data = [\n",
        "  [85,14,80,34,99,20,31,65,53,86,3,58,30,4,11,6,50,71,74,13],\n",
        "  [62,76,79,66,32],\n",
        "  [93,77,16,67,46,74,24,70],\n",
        "  [19,83,88,22,57,40,75,82,4,46],\n",
        "  [70,28,30,24,76,84,92,76,77,51,7,20,82,94,57],\n",
        "  [58,13,40,61,88,18,92,89,8,14,61,67,49,59,45,12,47,5],\n",
        "  [22,5,21,84,39,6,9,84,36,59,32,30,69,70,82,56,1],\n",
        "  [94,21,79,24,3,86],\n",
        "  [80,80,33,63,34,63],\n",
        "  [87,32,79,65,2,96,43,80,85,20,41,52,95,50,35,96,24,80]\n",
        "]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAy-O5F5GJff"
      },
      "source": [
        "Padding 처리를 해주면서 padding 전 길이도 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bysVQFzsGSsQ",
        "outputId": "0312a150-0a48-4498-98b8-d3a13ae0dfcc"
      },
      "source": [
        "max_len = len(max(data, key = len))\n",
        "print(f\"Maximum sequence length: {max_len}\")\n",
        "\n",
        "valid_lens = []\n",
        "for i, seq in enumerate(tqdm(data)):\n",
        "  valid_lens.append(len(seq))\n",
        "  if len(seq)< max_len:\n",
        "    data[i] = seq + [pad_id]*(max_len-len(seq))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:00<00:00, 5852.25it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "AMaximum sequence length: 20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TxvPnqd_GuqC",
        "outputId": "446edcd9-4054-4cae-8827-cae5ad3654d0"
      },
      "source": [
        "print(data)\n",
        "print(valid_lens)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[85, 14, 80, 34, 99, 20, 31, 65, 53, 86, 3, 58, 30, 4, 11, 6, 50, 71, 74, 13], [62, 76, 79, 66, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [93, 77, 16, 67, 46, 74, 24, 70, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [19, 83, 88, 22, 57, 40, 75, 82, 4, 46, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [70, 28, 30, 24, 76, 84, 92, 76, 77, 51, 7, 20, 82, 94, 57, 0, 0, 0, 0, 0], [58, 13, 40, 61, 88, 18, 92, 89, 8, 14, 61, 67, 49, 59, 45, 12, 47, 5, 0, 0], [22, 5, 21, 84, 39, 6, 9, 84, 36, 59, 32, 30, 69, 70, 82, 56, 1, 0, 0, 0], [94, 21, 79, 24, 3, 86, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [80, 80, 33, 63, 34, 63, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [87, 32, 79, 65, 2, 96, 43, 80, 85, 20, 41, 52, 95, 50, 35, 96, 24, 80, 0, 0]]\n",
            "[20, 5, 8, 10, 15, 18, 17, 6, 6, 18]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "quWKoS3vG3yW"
      },
      "source": [
        "위 데이터를 하나의 batch로 만들어 실습에 이용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9m_P4ocG_P-"
      },
      "source": [
        "batch = torch.LongTensor(data)\n",
        "batch_lens = torch.LongTensor(valid_lens)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FT05MBZcHKcx"
      },
      "source": [
        "## RNN 사용해보기\n",
        "RNN에 넣기 전 word embedding을 위한 embedding layer를 만듭니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oihA0mPdHSEm"
      },
      "source": [
        "embedding_size = 256\n",
        "embedding = nn.Embedding(vocab_size, embedding_size)\n",
        "\n",
        "batch_emb = embedding(batch)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aM83yzvHeaW"
      },
      "source": [
        "아래와 같이 RNN 모델 및 초기 hidden state를 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFVMaOS6HjUL"
      },
      "source": [
        "hidden_size = 512\n",
        "num_layers = 1\n",
        "num_dirs = 1\n",
        "\n",
        "rnn = nn.RNN(\n",
        "    input_size = embedding_size,\n",
        "    hidden_size = hidden_size,\n",
        "    num_layers = num_layers,\n",
        "    bidirectional = True if num_dirs>1 else False\n",
        ")\n",
        "\n",
        "h_0 = torch.zeros((num_layers*num_dirs, batch.shape[0], hidden_size))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFrVwgWSIEWf"
      },
      "source": [
        "RNN에 batch data를 넣으면 아래와 같이 2가지 output을 얻음\n",
        "- hidden_states: 각 time step에 해당되는 hidden state들의 묶음\n",
        "- h_n: 모든 sequence를 거치고 나온 마지막 hidden state"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zgLVuS9IYnk",
        "outputId": "93b9a520-328c-4235-82e3-62bdb1a42a0d"
      },
      "source": [
        "hidden_states, h_n = rnn(batch_emb.transpose(0, 1), h_0)\n",
        "\n",
        "print(hidden_states.shape)\n",
        "print(h_n.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([20, 10, 512])\n",
            "torch.Size([1, 10, 512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41Z0QsnzIoo6"
      },
      "source": [
        "## RNN 활용법\n",
        "마지막 hidden state를 이용하여 text classification task에 적용할 수 있음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jccX1Z3bIx3l",
        "outputId": "fb75d72f-6b96-452a-d2aa-32b841441274"
      },
      "source": [
        "num_classes = 2\n",
        "classification_layer = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "output = classification_layer(h_n.squeeze(0))\n",
        "print(output.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q4gJ-exXJBGz"
      },
      "source": [
        "각 time step에 대한 hidden state를 이용하여 token-level task를 수행할 수도 있음"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7oIscjUeJI5Z",
        "outputId": "99d203a7-d119-4abf-97ea-1c8dfd051d65"
      },
      "source": [
        "num_classes = 5\n",
        "entity_layer = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "output = entity_layer(hidden_states)\n",
        "print(output.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([20, 10, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myybCMV1JVIQ"
      },
      "source": [
        "## PackedSequence 사용법\n",
        "앞서 padding 처리했던 데이터를 다시 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eTT3kVE6KC9a",
        "outputId": "d1501161-7cc7-402d-9614-a1bb905fcc28"
      },
      "source": [
        "data"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[85, 14, 80, 34, 99, 20, 31, 65, 53, 86, 3, 58, 30, 4, 11, 6, 50, 71, 74, 13],\n",
              " [62, 76, 79, 66, 32, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " [93, 77, 16, 67, 46, 74, 24, 70, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " [19, 83, 88, 22, 57, 40, 75, 82, 4, 46, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " [70, 28, 30, 24, 76, 84, 92, 76, 77, 51, 7, 20, 82, 94, 57, 0, 0, 0, 0, 0],\n",
              " [58, 13, 40, 61, 88, 18, 92, 89, 8, 14, 61, 67, 49, 59, 45, 12, 47, 5, 0, 0],\n",
              " [22, 5, 21, 84, 39, 6, 9, 84, 36, 59, 32, 30, 69, 70, 82, 56, 1, 0, 0, 0],\n",
              " [94, 21, 79, 24, 3, 86, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " [80, 80, 33, 63, 34, 63, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              " [87, 32, 79, 65, 2, 96, 43, 80, 85, 20, 41, 52, 95, 50, 35, 96, 24, 80, 0, 0]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UK9RB4MKDqv",
        "outputId": "0b77575a-ef4c-4b98-a530-345fc4ca0180"
      },
      "source": [
        "sorted_lens, sorted_idx = batch_lens.sort(descending=True)\n",
        "sorted_batch = batch[sorted_idx]\n",
        "\n",
        "print(sorted_batch)\n",
        "print(sorted_lens)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[85, 14, 80, 34, 99, 20, 31, 65, 53, 86,  3, 58, 30,  4, 11,  6, 50, 71,\n",
            "         74, 13],\n",
            "        [58, 13, 40, 61, 88, 18, 92, 89,  8, 14, 61, 67, 49, 59, 45, 12, 47,  5,\n",
            "          0,  0],\n",
            "        [87, 32, 79, 65,  2, 96, 43, 80, 85, 20, 41, 52, 95, 50, 35, 96, 24, 80,\n",
            "          0,  0],\n",
            "        [22,  5, 21, 84, 39,  6,  9, 84, 36, 59, 32, 30, 69, 70, 82, 56,  1,  0,\n",
            "          0,  0],\n",
            "        [70, 28, 30, 24, 76, 84, 92, 76, 77, 51,  7, 20, 82, 94, 57,  0,  0,  0,\n",
            "          0,  0],\n",
            "        [19, 83, 88, 22, 57, 40, 75, 82,  4, 46,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0],\n",
            "        [93, 77, 16, 67, 46, 74, 24, 70,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0],\n",
            "        [94, 21, 79, 24,  3, 86,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0],\n",
            "        [80, 80, 33, 63, 34, 63,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0],\n",
            "        [62, 76, 79, 66, 32,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "          0,  0]])\n",
            "tensor([20, 18, 18, 17, 15, 10,  8,  6,  6,  5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rx9SzHn_Kig-"
      },
      "source": [
        "pack_padded_sequence를 이용하여 PackedSequence obkect를 사용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4s0XEFYmK2Yf",
        "outputId": "9981ebdf-41a8-4bfd-9693-80ea5d5f5484"
      },
      "source": [
        "sorted_batch_emb = embedding(sorted_batch)\n",
        "packed_batch = pack_padded_sequence(sorted_batch_emb.transpose(0, 1), sorted_lens)\n",
        "\n",
        "print(packed_batch)\n",
        "print(packed_batch[0].shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PackedSequence(data=tensor([[-1.5062, -1.2851,  0.0734,  ..., -0.5527, -0.8514, -0.0896],\n",
            "        [ 0.6514, -0.8530,  0.4354,  ...,  1.0369, -0.5971,  2.0721],\n",
            "        [ 0.5329, -1.6209,  1.2343,  ...,  1.0563, -0.9422,  0.7974],\n",
            "        ...,\n",
            "        [-0.7497, -1.8698, -0.0186,  ...,  0.3211, -0.3768, -0.2142],\n",
            "        [-0.3757,  1.1620, -1.4107,  ...,  0.2446, -0.3722, -0.0692],\n",
            "        [-1.8552, -1.0839, -0.0381,  ...,  0.9833,  0.1891,  0.5047]],\n",
            "       grad_fn=<PackPaddedSequenceBackward>), batch_sizes=tensor([10, 10, 10, 10, 10,  9,  7,  7,  6,  6,  5,  5,  5,  5,  5,  4,  4,  3,\n",
            "         1,  1]), sorted_indices=None, unsorted_indices=None)\n",
            "torch.Size([123, 256])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tcLQBMuLLpr",
        "outputId": "6336e305-0133-4e21-87db-41499f6a6416"
      },
      "source": [
        "packed_outputs, h_n = rnn(packed_batch, h_0)\n",
        "\n",
        "print(packed_outputs)\n",
        "print(packed_outputs[0].shape)\n",
        "print(h_n.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PackedSequence(data=tensor([[-0.0615,  0.4742, -0.6462,  ...,  0.1795,  0.5001,  0.4599],\n",
            "        [ 0.0331, -0.7967, -0.0922,  ..., -0.4491,  0.1275, -0.2828],\n",
            "        [ 0.0009,  0.0765, -0.2428,  ..., -0.0012, -0.2997,  0.3682],\n",
            "        ...,\n",
            "        [ 0.2131,  0.6968,  0.2036,  ..., -0.3289,  0.5836,  0.7497],\n",
            "        [ 0.7189,  0.2809, -0.2263,  ...,  0.7283, -0.6944, -0.2432],\n",
            "        [-0.2386,  0.1049,  0.3530,  ...,  0.3856, -0.2154,  0.2319]],\n",
            "       grad_fn=<CatBackward>), batch_sizes=tensor([10, 10, 10, 10, 10,  9,  7,  7,  6,  6,  5,  5,  5,  5,  5,  4,  4,  3,\n",
            "         1,  1]), sorted_indices=None, unsorted_indices=None)\n",
            "torch.Size([123, 512])\n",
            "torch.Size([1, 10, 512])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3KoukGBdLy1l"
      },
      "source": [
        "packed_output은 PackedSequence이므로 원래 output형태와 다름\n",
        "이를 다시 원래 형태로 바꿔주기 위해 pad_packed_sequence를 이용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1w8O3MfzLoOW",
        "outputId": "5081038e-1198-4016-f9ef-e23f776f4eac"
      },
      "source": [
        "outputs, outputs_lens = pad_packed_sequence(packed_outputs)\n",
        "\n",
        "print(outputs.shape)\n",
        "print(outputs_lens)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([20, 10, 512])\n",
            "tensor([20, 18, 18, 17, 15, 10,  8,  6,  6,  5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWWv-jI8L7vL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}